from .. import loader, utils
import aiohttp
from bs4 import BeautifulSoup
import re

#meta developer: Ksenon

@loader.tds
class EnhancedSearchMod(loader.Module):
    """üîç –ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Wikipedia –∏ Google"""

    strings = {"name": "EnhancedSearch"}

    async def search_wikipedia(self, query):
        url = f"https://ru.wikipedia.org/w/api.php?action=query&format=json&prop=extracts&exintro=1&explaintext=1&titles={query}"
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                data = await response.json()
                pages = data['query']['pages']
                page_id = next(iter(pages))
                if 'extract' in pages[page_id]:
                    extract = pages[page_id]['extract']
                    if extract:
                        summary = re.split(r'(?<=[.!?])\s+', extract)[0]  # –ë–µ—Ä—ë–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                        if len(summary) > 300:
                            summary = summary[:300] + '...'
                        return f"üìö <b>–ò–∑ –í–∏–∫–∏–ø–µ–¥–∏–∏:</b>\n{summary}\n<a href='https://ru.wikipedia.org/wiki/{query}'>–ü–æ–¥—Ä–æ–±–Ω–µ–µ...</a>\n\n"
        return ""

    async def search_google(self, query):
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(f"https://www.google.com/search?q={query}&hl=ru") as response:
                soup = BeautifulSoup(await response.text(), "html.parser")

        results = []
        seen_titles = set()
        for g in soup.find_all('div', class_='g'):
            title_elem = g.find('h3')
            snippet_elem = g.find('div', class_='VwiC3b')
            link_elem = g.find('a')
            
            if title_elem and snippet_elem and link_elem:
                title = title_elem.text
                if title in seen_titles:
                    continue
                seen_titles.add(title)
                
                snippet = snippet_elem.text.strip()
                link = link_elem['href']
                if snippet:
                    snippet = (snippet[:100] + '...') if len(snippet) > 100 else snippet
                results.append(f"üîó <b><a href='{link}'>{title}</a></b>\n{snippet}\n\n")

            if len(results) == 3:
                break

        return results

    @loader.command()
    async def search(self, message):
        """üîé –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .search <–∑–∞–ø—Ä–æ—Å>"""
        query = utils.get_args_raw(message)
        if not query:
            await utils.answer(message, "‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å!")
            return

        await utils.answer(message, "üïµÔ∏è –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é...")

        wiki_result = await self.search_wikipedia(query)
        google_results = await self.search_google(query)

        response = f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É '<b>{query}</b>':\n\n"
        response += wiki_result
        response += "<b>üåê –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ Google:</b>\n\n" + "".join(google_results)

        await utils.answer(message, response)