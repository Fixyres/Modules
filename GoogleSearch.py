from .. import loader, utils
import aiohttp
from bs4 import BeautifulSoup

#meta developer: Ksenon

@loader.tds
class GoogleSearchMod(loader.Module):
    """üîç –ú–æ–¥—É–ª—å –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ Google –∏ –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

    strings = {"name": "GoogleSearch"}

    @loader.command()
    async def gsearch(self, message):
        """üîé –ü–æ–∏—Å–∫ –≤ Google. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: .gsearch <–∑–∞–ø—Ä–æ—Å>"""
        query = utils.get_args_raw(message)
        if not query:
            await utils.answer(message, "‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å!")
            return

        await utils.answer(message, "üïµÔ∏è –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é...")

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }

        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(f"https://www.google.com/search?q={query}&hl=ru") as response:
                soup = BeautifulSoup(await response.text(), "html.parser")

        results = []
        for g in soup.find_all('div', class_='g'):
            title_elem = g.find('h3')
            snippet_elem = g.find('div', class_='VwiC3b')
            
            if title_elem and snippet_elem:
                title = title_elem.text
                snippet = snippet_elem.text.strip()
                results.append(f"<b>üìå {title}</b>\n{snippet}\n\n")

        if results:
            response = f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É '<b>{query}</b>':\n\n"
            response += "".join(results[:3])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            await utils.answer(message, response)
        else:
            await utils.answer(message, "üòï –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")